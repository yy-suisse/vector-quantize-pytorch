{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e07b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.evaluation as eval_utils\n",
    "import utils.model as model_utils\n",
    "import torch\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50e8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hits_at_k(ranks, ks=np.arange(1,11)):\n",
    "    ranks = np.array(ranks)\n",
    "    return np.array([(ranks < k).mean() for k in ks]), ks\n",
    "\n",
    "def plot_hits_at_k(model_ranks, title, type = None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for model_name in MODEL_NAME.keys():\n",
    "        if type:\n",
    "            top_k_accuracy , ks = compute_hits_at_k(model_ranks[model_name][type])\n",
    "        else:\n",
    "            top_k_accuracy, ks = compute_hits_at_k(model_ranks[model_name])\n",
    "        plt.plot(ks, top_k_accuracy, label=model_name)\n",
    "\n",
    "    plt.xticks(ks)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Hit at k\")\n",
    "    plt.legend()\n",
    "    plt.title(title + \": Hits@k Comparison\")\n",
    "    # Move legend outside\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to not cut off labels\n",
    "    plt.show()\n",
    "\n",
    "def compute_mmr(ranks):\n",
    "    reciprocal_ranks = 1/(ranks + 1)\n",
    "    return reciprocal_ranks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7618335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all info\n",
    "Config = model_utils.Config()\n",
    "df_concept_all = pl.read_parquet(Config.concept_parquet)\n",
    "df_concept_all_idx = set(df_concept_all[\"idx\"].unique().to_list())\n",
    "\n",
    "df_concept_train = pl.read_parquet(Config.train_triplet)\n",
    "df_concept_train_idx = set(df_concept_train[\"idx\"].unique().to_list())\n",
    "\n",
    "df_concept_test_idx = df_concept_all_idx - df_concept_train_idx\n",
    "df_concept_test = list(df_concept_test_idx)\n",
    "\n",
    "id2idx = dict(zip(df_concept_all[\"id\"], df_concept_all[\"idx\"]))\n",
    "\n",
    "df_concept_test_fd = df_concept_all.filter(pl.col(\"idx\").is_in(df_concept_test)).filter(pl.col(\"status\") == \"defined\")[\"idx\"].unique().to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4635ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_SAVE = \"D:/finetune_sbert_new/1Membeddings/lora_16_quantized/\"\n",
    "embedding_name = \"sapbert_lora_triplet16\"\n",
    "BENCHMARK_PATH = \"D:/finetune_sbert_new/benchmark_jamil/\"\n",
    "embeddings = torch.load(FILE_PATH_SAVE + embedding_name + \"_quantized.pt\")\n",
    "embedding_exp_q = embeddings[\"embedding_exp_q\"]\n",
    "embedding_label_q = embeddings[\"embedding_label_q\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7e4c1",
   "metadata": {},
   "source": [
    "# task 1:  retrieve label given expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5968cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_matrix = torch.tensor(query_matrix, dtype=torch.float32)\n",
      "c:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidate_matrix = torch.tensor(candidate_matrix, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/435 (0-100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# task 1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[43meval_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k_array_by_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_concept_test_fd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_exp_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_label_q\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:26\u001b[0m, in \u001b[0;36mtop_k_array_by_batch\u001b[1;34m(id_concept_test_set, query_matrix, candidate_matrix, batch_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m query_batch \u001b[38;5;241m=\u001b[39m query_matrix[batch_indices]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Compute scores\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_matrix_T\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Sort scores descending\u001b[39;00m\n\u001b[0;32m     29\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margsort(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# task 1\n",
    "rank = eval_utils.top_k_array_by_batch(df_concept_test_fd, embedding_exp_q, embedding_label_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049ed284",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_mmr(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54a6c8",
   "metadata": {},
   "source": [
    "# task 2, 3\n",
    "- task 2: retrieve synonyme given expression\n",
    "- task 3: retrieve synonyme given label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bb1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_SAVE = \"D:/finetune_sbert_new/1Membeddings/lora_16_quantized/\"\n",
    "embedding_name = \"sapbert_lora_triplet16\"\n",
    "syn_embeddings = torch.load(FILE_PATH_SAVE + embedding_name + \"_syn_quantized.pt\")\n",
    "\n",
    "       \n",
    "embedding_exp = embeddings[\"embedding_exp_q\"]\n",
    "embedding_label = embeddings[\"embedding_label_q\"]\n",
    "\n",
    "\n",
    "embedding_syn_idx = syn_embeddings[\"idx\"]\n",
    "embedding_syn_matrix = syn_embeddings[\"expressions_embeddings\"]\n",
    "\n",
    "# Determine test indices\n",
    "embedding_syn_test_idx = list(set(embedding_syn_idx).intersection(set(df_concept_test_fd)))\n",
    "\n",
    "# Compute rankings\n",
    "rank_w_exp = eval_utils.top_k_array_syn(embedding_syn_test_idx, embedding_syn_idx, embedding_syn_matrix, embedding_exp, device=Config.device)\n",
    "rank_w_label = eval_utils.top_k_array_syn(embedding_syn_test_idx, embedding_syn_idx, embedding_syn_matrix, embedding_label, device=Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09cf362",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_mmr(rank_w_exp))\n",
    "print(compute_mmr(rank_w_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f25a6",
   "metadata": {},
   "source": [
    "# task 4:  hierarchical similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_hierarchical_similarity = pd.read_table(BENCHMARK_PATH + \"hierarchical_similarity_benchmark.tsv\")\n",
    "df_hierarchical_similarity = pl.from_pandas(df_hierarchical_similarity)\n",
    "df_hierarchical_similarity = df_hierarchical_similarity.select(pl.col(\"sctid\").cast(pl.String), pl.col(\"close_sctid\").cast(pl.String), pl.col(\"far_sctid\").cast(pl.String))\n",
    "\n",
    "\n",
    "embedding_exp = embeddings[\"embedding_exp_q\"]\n",
    "embedding_label = embeddings[\"embedding_label_q\"]\n",
    "\n",
    "accuracy_exp = eval_utils.compute_hierarchical_similarity(df_hierarchical_similarity, id2idx, embedding_exp)\n",
    "accuracy_label = eval_utils.compute_hierarchical_similarity(df_hierarchical_similarity, id2idx, embedding_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2468b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hierarchical similarity accuracy for expressions: \", accuracy_exp)\n",
    "print(\"Hierarchical similarity accuracy for labels: \", accuracy_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8a140",
   "metadata": {},
   "source": [
    "# task 5: semantic composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00a6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def compute_semantic_composition(df_semantic_composition, id2idx, embeddings_exp_ft, list_idx_all_pre_set):\n",
    "    device = embeddings_exp_ft.device\n",
    "    embedding_dim = embeddings_exp_ft.shape[1]\n",
    "    idx_pre_set = set(list_idx_all_pre_set)\n",
    "\n",
    "    list_anchor_idx = []\n",
    "    list_composed_embedding = []\n",
    "\n",
    "    # 1. Build all anchor and composed embeddings\n",
    "    for row in df_semantic_composition.iter_rows():\n",
    "        anchor_id = str(row[0])\n",
    "        if anchor_id not in id2idx:\n",
    "            continue\n",
    "        anchor_idx = id2idx[anchor_id]\n",
    "\n",
    "        try:\n",
    "            related_ids = ast.literal_eval(row[1])\n",
    "        except (ValueError, SyntaxError):\n",
    "            continue\n",
    "\n",
    "        valid_related_indices = [\n",
    "            id2idx[str(rid)] for rid in related_ids if str(rid) in id2idx\n",
    "        ]\n",
    "\n",
    "        if not valid_related_indices:\n",
    "            continue\n",
    "\n",
    "        related_tensor = embeddings_exp_ft[valid_related_indices]\n",
    "        composed = related_tensor.mean(dim=0)\n",
    "\n",
    "        list_anchor_idx.append(anchor_idx)\n",
    "        list_composed_embedding.append(composed)\n",
    "\n",
    "    # 2. Stack all composed vectors and anchor indices\n",
    "    composed_matrix = torch.stack(list_composed_embedding)  # [N, D]\n",
    "    anchor_indices = torch.tensor(list_anchor_idx, dtype=torch.long, device=device)  # [N]\n",
    "\n",
    "    # 3. Compute similarity in batch: [N, D] x [D, All] => [N, All]\n",
    "    similarity_scores = torch.matmul(composed_matrix, embeddings_exp_ft.T)  # [N, Total]\n",
    "\n",
    "    # 4. Get ranking positions\n",
    "    top_k_pre = []\n",
    "    idx_all_pre_tensor = torch.tensor(list(list_idx_all_pre_set), dtype=torch.long, device=device)\n",
    "\n",
    "    for i in range(similarity_scores.shape[0]):\n",
    "        scores = similarity_scores[i]\n",
    "        sorted_indices = torch.argsort(scores, descending=True)\n",
    "\n",
    "        # Efficient filtering for pre-defined only\n",
    "        mask = torch.isin(sorted_indices, idx_all_pre_tensor)\n",
    "        sorted_pre = sorted_indices[mask]\n",
    "\n",
    "        anchor_idx = anchor_indices[i]\n",
    "        match = (sorted_pre == anchor_idx).nonzero(as_tuple=True)[0]\n",
    "        rank = match.item() if len(match) > 0 else -1\n",
    "        top_k_pre.append(rank)\n",
    "\n",
    "    return np.array(top_k_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7ce8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semantic_composition = pd.read_table(BENCHMARK_PATH + \"semantic_composition_benchmark.tsv\")\n",
    "df_semantic_composition = pl.from_pandas(df_semantic_composition)\n",
    "df_semantic_composition = df_semantic_composition.select(\n",
    "    pl.col(\"id_node\"),\n",
    "    pl.col(\"parents_ids\"),\n",
    ")\n",
    "\n",
    "# Prepare the set of indices\n",
    "list_idx_all_pre = df_concept_all.filter(pl.col(\"concept_type\") == \"SCT_PRE\")[\"idx\"].unique().to_list()\n",
    "list_idx_all_pre_set = set(list_idx_all_pre)\n",
    "\n",
    "embedding_exp = embeddings[\"embedding_exp_q\"].to(device=Config.device)\n",
    "embedding_label = embeddings[\"embedding_label_q\"].to(device=Config.device)\n",
    "\n",
    "# mr_exp = eval_utils.compute_semantic_composition(df_semantic_composition, id2idx, embedding_exp, list_idx_all_pre_set)\n",
    "# mr_label = eval_utils.compute_semantic_composition(df_semantic_composition, id2idx, embedding_label, list_idx_all_pre_set)\n",
    "mr_exp = compute_semantic_composition(df_semantic_composition, id2idx, embedding_exp, list_idx_all_pre_set)\n",
    "mr_label = compute_semantic_composition(df_semantic_composition, id2idx, embedding_label, list_idx_all_pre_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d84793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20483985866704937\n",
      "0.19029802637027435\n"
     ]
    }
   ],
   "source": [
    "print(compute_mmr(mr_exp))\n",
    "print(compute_mmr(mr_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a556413",
   "metadata": {},
   "source": [
    "# IS_A invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0278d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_matrix = torch.tensor(query_matrix, dtype=torch.float32).to(device)\n",
      "c:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidate_matrix = torch.tensor(candidate_matrix, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0/46410)\n",
      "Processing batch 1000/46410)\n",
      "Processing batch 2000/46410)\n",
      "Processing batch 3000/46410)\n",
      "Processing batch 4000/46410)\n",
      "Processing batch 5000/46410)\n",
      "Processing batch 6000/46410)\n",
      "Processing batch 7000/46410)\n",
      "Processing batch 8000/46410)\n",
      "Processing batch 9000/46410)\n",
      "Processing batch 10000/46410)\n",
      "Processing batch 11000/46410)\n",
      "Processing batch 12000/46410)\n",
      "Processing batch 13000/46410)\n",
      "Processing batch 14000/46410)\n",
      "Processing batch 15000/46410)\n",
      "Processing batch 16000/46410)\n",
      "Processing batch 17000/46410)\n",
      "Processing batch 18000/46410)\n",
      "Processing batch 19000/46410)\n",
      "Processing batch 20000/46410)\n",
      "Processing batch 21000/46410)\n",
      "Processing batch 22000/46410)\n",
      "Processing batch 23000/46410)\n",
      "Processing batch 24000/46410)\n",
      "Processing batch 25000/46410)\n",
      "Processing batch 26000/46410)\n",
      "Processing batch 27000/46410)\n",
      "Processing batch 28000/46410)\n",
      "Processing batch 29000/46410)\n",
      "Processing batch 30000/46410)\n",
      "Processing batch 31000/46410)\n",
      "Processing batch 32000/46410)\n",
      "Processing batch 33000/46410)\n",
      "Processing batch 34000/46410)\n",
      "Processing batch 35000/46410)\n",
      "Processing batch 36000/46410)\n",
      "Processing batch 37000/46410)\n",
      "Processing batch 38000/46410)\n",
      "Processing batch 39000/46410)\n",
      "Processing batch 40000/46410)\n",
      "Processing batch 41000/46410)\n",
      "Processing batch 42000/46410)\n",
      "Processing batch 43000/46410)\n",
      "Processing batch 44000/46410)\n",
      "Processing batch 45000/46410)\n",
      "Processing batch 46000/46410)\n",
      "Processing batch 0/46410)\n",
      "Processing batch 1000/46410)\n",
      "Processing batch 2000/46410)\n",
      "Processing batch 3000/46410)\n",
      "Processing batch 4000/46410)\n",
      "Processing batch 5000/46410)\n",
      "Processing batch 6000/46410)\n",
      "Processing batch 7000/46410)\n",
      "Processing batch 8000/46410)\n",
      "Processing batch 9000/46410)\n",
      "Processing batch 10000/46410)\n",
      "Processing batch 11000/46410)\n",
      "Processing batch 12000/46410)\n",
      "Processing batch 13000/46410)\n",
      "Processing batch 14000/46410)\n",
      "Processing batch 15000/46410)\n",
      "Processing batch 16000/46410)\n",
      "Processing batch 17000/46410)\n",
      "Processing batch 18000/46410)\n",
      "Processing batch 19000/46410)\n",
      "Processing batch 20000/46410)\n",
      "Processing batch 21000/46410)\n",
      "Processing batch 22000/46410)\n",
      "Processing batch 23000/46410)\n",
      "Processing batch 24000/46410)\n",
      "Processing batch 25000/46410)\n",
      "Processing batch 26000/46410)\n",
      "Processing batch 27000/46410)\n",
      "Processing batch 28000/46410)\n",
      "Processing batch 29000/46410)\n",
      "Processing batch 30000/46410)\n",
      "Processing batch 31000/46410)\n",
      "Processing batch 32000/46410)\n",
      "Processing batch 33000/46410)\n",
      "Processing batch 34000/46410)\n",
      "Processing batch 35000/46410)\n",
      "Processing batch 36000/46410)\n",
      "Processing batch 37000/46410)\n",
      "Processing batch 38000/46410)\n",
      "Processing batch 39000/46410)\n",
      "Processing batch 40000/46410)\n",
      "Processing batch 41000/46410)\n",
      "Processing batch 42000/46410)\n",
      "Processing batch 43000/46410)\n",
      "Processing batch 44000/46410)\n",
      "Processing batch 45000/46410)\n",
      "Processing batch 46000/46410)\n"
     ]
    }
   ],
   "source": [
    "embedding_new_exp = torch.load(FILE_PATH_SAVE + embedding_name  + \"_new_exp_quantized.pt\")\n",
    "\n",
    "rank_exp = eval_utils.top_k_exp_by_batch(embedding_new_exp[\"idx_true\"], embedding_new_exp[\"new_expressions_embeddings\"], embedding_exp, batch_size=1000, device=Config.device)\n",
    "rank_label = eval_utils.top_k_exp_by_batch(embedding_new_exp[\"idx_true\"], embedding_new_exp[\"new_expressions_embeddings\"], embedding_label, batch_size=1000, device=Config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3642a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4119303841972174\n",
      "0.18768916867913096\n"
     ]
    }
   ],
   "source": [
    "print(compute_mmr(rank_exp))\n",
    "print(compute_mmr(rank_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
