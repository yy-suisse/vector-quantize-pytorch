{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98d54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import utils.embed_concepts as embed_concepts\n",
    "import torch\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393a1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CONFIG = {\n",
    "    \"path_all_concept\": \"D:/lora_finetune_eval/basic_info/concept_all.parquet\",\n",
    "    \"path_is_a\" : \"D:/lora_finetune_eval/basic_info/graph_is_a_invariant.csv\",\n",
    "    \"mapped_concept\": \"D:/lora_finetune_eval/basic_info/mapped_concepts_2025-04-01.csv\",\n",
    "    \"training_triplet_idx\": \"D:/lora_finetune_eval/basic_info/training_anchor_idx_1M.parquet\",\n",
    "\n",
    "    \"icd_snomed\" : \"D:/lora_finetune_eval/icd_snomed/\",\n",
    "\n",
    "    \"embedding_save_path\": \"D:/lora_finetune_eval/embedding_by_model/\",\n",
    "    \"syn_embedding_save_path\": \"D:/lora_finetune_eval/syn_embedding_by_model/\",\n",
    "    \"new_exp_embedding_save_path\": \"D:/lora_finetune_eval/new_exp_embedding_by_model/\",\n",
    "    \"embedding_icd_snomed_save_path\": \"D:/lora_finetune_eval/embedding_icd_snomed_by_model/\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee9c6e",
   "metadata": {},
   "source": [
    "# 1. embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49ae126",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_concept = pl.read_parquet(FILE_CONFIG[\"path_all_concept\"])\n",
    "new_expression_is_a = pl.read_csv(FILE_CONFIG[\"path_is_a\"])\n",
    "df_syn_defined = all_concept.explode(\"syns_list\").filter(pl.col(\"status\") == \"defined\").drop_nulls()\n",
    "\n",
    "expressions = all_concept['expression'].to_list()\n",
    "labels = all_concept['n.label'].to_list()\n",
    "\n",
    "new_exp = new_expression_is_a['new_exp'].to_list()\n",
    "idx_true = new_expression_is_a['idx'].to_list()\n",
    "\n",
    "syns = df_syn_defined[\"syns_list\"].to_list()\n",
    "idx = df_syn_defined[\"idx\"].to_list()\n",
    "\n",
    "snomed_info = pl.read_csv(FILE_CONFIG[\"icd_snomed\"] + \"snomed_info.csv\")\n",
    "icd_info = pl.read_csv(FILE_CONFIG[\"icd_snomed\"] + \"icd_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf658d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "model_config = embed_concepts.MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping finetune_1M: Embeddings already saved at D:/lora_finetune_eval/embedding_by_model/finetune_1M.pt\n",
      "Skipping baseline: Embeddings already saved at D:/lora_finetune_eval/embedding_by_model/baseline.pt\n",
      "Skipping clinicalbert: Embeddings already saved at D:/lora_finetune_eval/embedding_by_model/clinicalbert.pt\n",
      "Skipping bio_clinicalbert: Embeddings already saved at D:/lora_finetune_eval/embedding_by_model/bio_clinicalbert.pt\n",
      "Skipping e5_base: Embeddings already saved at D:/lora_finetune_eval/embedding_by_model/e5_base.pt\n",
      "Skipping gte_base: Embeddings already saved at D:/lora_finetune_eval/embedding_by_model/gte_base.pt\n",
      "\n",
      "Encoding with sapbert...\n",
      "Encoding expressions... sapbert\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf691c958ff14834b50ef2967fb16140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/3068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# expression and label\n",
    "for model_key in model_config.keys():\n",
    "    save_path = FILE_CONFIG[\"embedding_save_path\"] + model_key + \".pt\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Skipping {model_key}: Embeddings already saved at {save_path}\")\n",
    "        continue  # skip to next model\n",
    "\n",
    "    print(f\"\\nEncoding with {model_key}...\")\n",
    "\n",
    "    model = embed_concepts.load_model(model_key, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Encoding expressions...\", model_key)\n",
    "        embeddings_exp = model.encode(expressions, batch_size=batch_size)\n",
    "        print(\"Encoding labels...\", model_key)\n",
    "        embeddings_labels = model.encode(labels, batch_size=batch_size)\n",
    "\n",
    "    embed_concepts.save_embeddings({\n",
    "                    \"model_name\": model_key,\n",
    "                    \"expressions_embeddings\": embeddings_exp.cpu(),\n",
    "                    \"labels_embeddings\": embeddings_labels.cpu(),\n",
    "                }, save_path)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synonyms\n",
    "syns = df_syn_defined[\"syns_list\"].to_list()\n",
    "idx = df_syn_defined[\"idx\"].to_list()\n",
    "\n",
    "for model_key in model_config.keys():\n",
    "    save_path = FILE_CONFIG[\"syn_embedding_save_path\"] + model_key + \".pt\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Skipping {model_key}: Embeddings already saved at {save_path}\")\n",
    "        continue  # skip to next model\n",
    "\n",
    "    print(f\"\\nEncoding with {model_key}...\")\n",
    "    \n",
    "    model = embed_concepts.load_model(model_key, device=device)\n",
    "    with torch.no_grad():\n",
    "        print(\"Encoding synonyms...\", model_key)\n",
    "        embeddings_syn = model.encode(syns, batch_size=batch_size)\n",
    "\n",
    "    embed_concepts.save_embeddings({\n",
    "        \"model_name\": model_key,\n",
    "        \"synonyms\": syns,\n",
    "        \"expressions_embeddings\": embeddings_syn.cpu(),\n",
    "        \"idx\": idx,\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f628d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new exp\n",
    "for model_key in model_config.keys():\n",
    "    save_path = FILE_CONFIG[\"new_exp_embedding_save_path\"] + model_key + \".pt\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Skipping {model_key}: Embeddings already saved at {save_path}\")\n",
    "        continue  # skip to next model\n",
    "\n",
    "    print(f\"\\nEncoding with {model_key}...\")\n",
    "    model = embed_concepts.load_model(model_key, device=device)\n",
    "    with torch.no_grad():\n",
    "        print(\"Encoding new expressions...\", model_key)\n",
    "\n",
    "        embeddings_exp_new = model.encode(new_exp, batch_size=batch_size)\n",
    "    embed_concepts.save_embeddings({\n",
    "                    \"model_name\": model_key,\n",
    "                    \"new_expressions_embeddings\": embeddings_exp_new.cpu(),\n",
    "                    \"idx_true\": idx_true\n",
    "                }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# icd and snomed matching\n",
    "snomed_labels = snomed_info[\"SNOMED_label\"].to_list()\n",
    "icd_labels = icd_info[\"ICD_label\"].to_list()\n",
    "\n",
    "for model_key in model_config.keys():\n",
    "    save_path = FILE_CONFIG[\"embedding_icd_snomed_save_path\"] + model_key + \".pt\"\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Skipping {model_key}: Embeddings already saved at {save_path}\")\n",
    "        continue  # skip to next model\n",
    "\n",
    "    print(f\"\\nEncoding with {model_key}...\")\n",
    "    print(\"Encoding ICD...\")\n",
    "    model = embed_concepts.load_model(model_key, device=device)\n",
    "    with torch.no_grad():\n",
    "        embeddings_icd = model.encode(icd_labels, batch_size=batch_size)\n",
    "        print(\"Encoding SNOMED...\")\n",
    "        embeddings_snomed = model.encode(snomed_labels, batch_size=batch_size)\n",
    "\n",
    "    embed_concepts.save_embeddings({\n",
    "        \"model_name\": model_key,\n",
    "        \"icd_embeddings\": embeddings_icd.cpu(),\n",
    "        \"snomed_embeddings\": embeddings_snomed.cpu(),\n",
    "    }, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
