{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db09741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import polars as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from vector_quantize_pytorch import ResidualVQ\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from utils.file_config import FILE_CONFIG as fc\n",
    "import utils.evaluation as eval_utils\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "# === Config ===\n",
    "class Config:\n",
    "    alpha = 0\n",
    "    num_epochs = 100\n",
    "    batch_size = 2048*32\n",
    "    lr = 3e-4\n",
    "    dim = 768\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed = 1234\n",
    "    codebook_config =[\n",
    "    {'num_codebooks': 5, 'codebook_size': 512, 'use_cosine': True},\n",
    "    {'num_codebooks': 6, 'codebook_size': 512, 'use_cosine': True},\n",
    "    {'num_codebooks': 7, 'codebook_size': 512, 'use_cosine': True},\n",
    "    {'num_codebooks': 5, 'codebook_size': 1024, 'use_cosine': True},\n",
    "    {'num_codebooks': 6, 'codebook_size': 1024, 'use_cosine': True},\n",
    "    {'num_codebooks': 7, 'codebook_size': 1024, 'use_cosine': True},\n",
    "\n",
    "    {'num_codebooks': 5, 'codebook_size': 512, 'use_cosine': False},\n",
    "    {'num_codebooks': 6, 'codebook_size': 512, 'use_cosine': False},\n",
    "    {'num_codebooks': 7, 'codebook_size': 512, 'use_cosine': False},\n",
    "    {'num_codebooks': 5, 'codebook_size': 1024, 'use_cosine': False},\n",
    "    {'num_codebooks': 6, 'codebook_size': 1024, 'use_cosine': False},\n",
    "    {'num_codebooks': 7, 'codebook_size': 1024, 'use_cosine': False},\n",
    "]\n",
    "\n",
    "torch.manual_seed(Config.seed)\n",
    "\n",
    "\n",
    "def load_embeddings(file_config, model, config):\n",
    "    df_concept_all = pl.read_parquet(file_config[\"path_all_concept\"])\n",
    "    df_mapped = pl.read_csv(file_config[\"mapped_concept\"])\n",
    "    idx_mapped = df_mapped.join(df_concept_all, left_on=\"n.id\", right_on=\"id\")[\"idx\"].unique().to_list()\n",
    "    embedding_path = file_config[\"embedding_save_path\"] + f\"/{model}.pt\"\n",
    "    full_embeddings_l = torch.load(embedding_path)[\"labels_embeddings\"].to(config.device)\n",
    "    full_embeddings_exp = torch.load(embedding_path)[\"expressions_embeddings\"].to(config.device)\n",
    "    mapped_embeddings = full_embeddings_l[idx_mapped, :]\n",
    "\n",
    "    return full_embeddings_l, full_embeddings_exp, mapped_embeddings\n",
    "\n",
    "\n",
    "def train(model, train_loader, config):\n",
    "    \n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(f\"\\n=== Epoch {epoch + 1}/{config.num_epochs} ===\")\n",
    "        epoch_losses = []\n",
    "        for x_batch in train_loader:\n",
    "\n",
    "            x = x_batch[0].to(config.device)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            quantized, _, _ = model(x)\n",
    "            # out = out.clamp(-1., 1.)\n",
    "            if config.use_cosine:\n",
    "                loss = 1 - F.cosine_similarity(x, quantized, dim=-1).mean()\n",
    "            else:\n",
    "                loss = F.mse_loss(x, quantized)\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        print(f\"Epoch {epoch+1} | Avg batch loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate(model, embeddings):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.to(Config.device)\n",
    "        quantized, indices, _ = model(embeddings)\n",
    "        cos_sim = F.cosine_similarity(embeddings, quantized, dim=-1).mean()\n",
    "        print(f\"Average cosine similarity: {cos_sim.item():.4f}\")\n",
    "        return quantized, indices\n",
    "    \n",
    "def get_dataloader(embeddings,config):\n",
    "    dataset = TensorDataset(embeddings)\n",
    "    return DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "def run_all_configs(config_list, train_loader, base_config):\n",
    "    results = []\n",
    "\n",
    "    for conf in config_list:\n",
    "        cfg = deepcopy(base_config)\n",
    "        cfg.num_codebooks = conf[\"num_codebooks\"]\n",
    "        cfg.codebook_size = conf[\"codebook_size\"]\n",
    "        cfg.use_cosine = conf[\"use_cosine\"]\n",
    "\n",
    "        config_id = f\"{cfg.num_codebooks}x{cfg.codebook_size}_{'cos' if cfg.use_cosine else 'l2'}\"\n",
    "        print(f\"\\n=== Training {config_id} ===\")\n",
    "\n",
    "        # Instantiate model\n",
    "        model = ResidualVQ(\n",
    "            dim=cfg.dim,\n",
    "            num_quantizers=cfg.num_codebooks,\n",
    "            codebook_size=cfg.codebook_size,\n",
    "            learnable_codebook=True,\n",
    "            ema_update=False,\n",
    "            # kmeans_init=True,\n",
    "            # kmeans_iters=10,\n",
    "            use_cosine_sim=cfg.use_cosine\n",
    "        ).to(cfg.device)\n",
    "\n",
    "        # Train\n",
    "        model = train(model, train_loader, cfg)\n",
    "\n",
    "        # Save result\n",
    "        torch.save(model.state_dict(), f\"rvq_{config_id}.pt\")\n",
    "        results.append({\n",
    "            \"config\": conf,\n",
    "            \"config_id\": config_id,\n",
    "            \"model\": model\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rvq_vanilla = ResidualVQ(\n",
    "    dim=768,\n",
    "    num_quantizers=4,\n",
    "    codebook_size=512,\n",
    "    learnable_codebook=True,\n",
    "    ema_update=False,\n",
    "    kmeans_init=True,\n",
    "    kmeans_iters=10,\n",
    ").to(Config.device)\n",
    "\n",
    "rvq_cosine = ResidualVQ(\n",
    "    dim=768,\n",
    "    num_quantizers=4,\n",
    "    codebook_size=512,\n",
    "    learnable_codebook=True,\n",
    "    ema_update=False,\n",
    "    use_cosine_sim=True,\n",
    ").to(Config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a930725",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "# === Dataset & DataLoader ===\n",
    "full_embeddings_l,full_embeddings_exp, mapped_embeddings = load_embeddings(file_config=fc, model= \"sapbert_lora_triplet16\", config=cfg)\n",
    "train_loader = get_dataloader(torch.concat((full_embeddings_l, full_embeddings_exp)), cfg)\n",
    "\n",
    "# === train ===\n",
    "\n",
    "cfg.use_cosine = False  # Set to True if you want to use cosine similarity\n",
    "rvq_vanilla = train(rvq_vanilla, train_loader, cfg)\n",
    "\n",
    "cfg.use_cosine = True  # Set to True if you want to use cosine similarity\n",
    "rvq_cosine = train(rvq_cosine, train_loader, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f71b7",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c4da650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concept_all = pl.read_parquet(fc[\"path_all_concept\"])\n",
    "df_concept_all_idx = set(df_concept_all[\"idx\"].unique().to_list())\n",
    "\n",
    "df_concept_train = pl.read_parquet(fc[\"training_triplet_idx\"])\n",
    "df_concept_train_idx = set(df_concept_train[\"idx\"].unique().to_list())\n",
    "\n",
    "df_concept_test_idx = df_concept_all_idx - df_concept_train_idx\n",
    "df_concept_test = list(df_concept_test_idx)\n",
    "\n",
    "id2idx = dict(zip(df_concept_all[\"id\"], df_concept_all[\"idx\"]))\n",
    "\n",
    "df_concept_test_fd = df_concept_all.filter(pl.col(\"idx\").is_in(df_concept_test)).filter(pl.col(\"status\") == \"defined\")[\"idx\"].unique().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae9e24",
   "metadata": {},
   "source": [
    "# eval task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c112fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrrs_1 = []\n",
    "models_1 = []\n",
    "ranks_1 = {}\n",
    "\n",
    "embeddings = torch.load(fc[\"embedding_save_path\"] + f\"/sapbert_lora_triplet16.pt\")\n",
    "embedding_exp = embeddings[\"expressions_embeddings\"]\n",
    "embedding_label = embeddings[\"labels_embeddings\"]\n",
    "embedding_exp_q,_ = evaluate(rvq_vanilla, embedding_exp)\n",
    "embedding_label_q,_ = evaluate(rvq_vanilla, embedding_label)\n",
    "rank = eval_utils.top_k_array_by_batch(df_concept_test_fd, embedding_exp_q, embedding_label_q,cfg.device, 100)\n",
    "mrr_rank = eval_utils.compute_mmr(rank)\n",
    "mrrs_1.append(mrr_rank)\n",
    "models_1.append(\"vanilla_4_512\")\n",
    "ranks_1[\"vanilla_4_512\"] = rank\n",
    "print(f\"MRR: {mrr_rank}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a91917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg.use_cosine = True  # Set to True if you want to use cosine similarity\n",
    "rvq_cosine = train(rvq_cosine, train_loader, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity: 0.7597\n",
      "Average cosine similarity: 0.7502\n",
      "Processing batch 1/435 (0-100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_matrix = torch.tensor(query_matrix, dtype=torch.float32).to(device)\n",
      "c:\\Users\\yy\\Desktop\\quantizer\\vector-quantize-pytorch\\utils\\evaluation.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  candidate_matrix = torch.tensor(candidate_matrix, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/435 (100-200)\n",
      "Processing batch 3/435 (200-300)\n",
      "Processing batch 4/435 (300-400)\n",
      "Processing batch 5/435 (400-500)\n",
      "Processing batch 6/435 (500-600)\n",
      "Processing batch 7/435 (600-700)\n",
      "Processing batch 8/435 (700-800)\n",
      "Processing batch 9/435 (800-900)\n",
      "Processing batch 10/435 (900-1000)\n",
      "Processing batch 11/435 (1000-1100)\n",
      "Processing batch 12/435 (1100-1200)\n",
      "Processing batch 13/435 (1200-1300)\n",
      "Processing batch 14/435 (1300-1400)\n",
      "Processing batch 15/435 (1400-1500)\n",
      "Processing batch 16/435 (1500-1600)\n",
      "Processing batch 17/435 (1600-1700)\n",
      "Processing batch 18/435 (1700-1800)\n",
      "Processing batch 19/435 (1800-1900)\n",
      "Processing batch 20/435 (1900-2000)\n",
      "Processing batch 21/435 (2000-2100)\n",
      "Processing batch 22/435 (2100-2200)\n",
      "Processing batch 23/435 (2200-2300)\n",
      "Processing batch 24/435 (2300-2400)\n",
      "Processing batch 25/435 (2400-2500)\n",
      "Processing batch 26/435 (2500-2600)\n",
      "Processing batch 27/435 (2600-2700)\n",
      "Processing batch 28/435 (2700-2800)\n",
      "Processing batch 29/435 (2800-2900)\n",
      "Processing batch 30/435 (2900-3000)\n",
      "Processing batch 31/435 (3000-3100)\n",
      "Processing batch 32/435 (3100-3200)\n",
      "Processing batch 33/435 (3200-3300)\n",
      "Processing batch 34/435 (3300-3400)\n",
      "Processing batch 35/435 (3400-3500)\n",
      "Processing batch 36/435 (3500-3600)\n",
      "Processing batch 37/435 (3600-3700)\n",
      "Processing batch 38/435 (3700-3800)\n",
      "Processing batch 39/435 (3800-3900)\n",
      "Processing batch 40/435 (3900-4000)\n",
      "Processing batch 41/435 (4000-4100)\n",
      "Processing batch 42/435 (4100-4200)\n",
      "Processing batch 43/435 (4200-4300)\n",
      "Processing batch 44/435 (4300-4400)\n",
      "Processing batch 45/435 (4400-4500)\n",
      "Processing batch 46/435 (4500-4600)\n",
      "Processing batch 47/435 (4600-4700)\n",
      "Processing batch 48/435 (4700-4800)\n",
      "Processing batch 49/435 (4800-4900)\n",
      "Processing batch 50/435 (4900-5000)\n",
      "Processing batch 51/435 (5000-5100)\n",
      "Processing batch 52/435 (5100-5200)\n",
      "Processing batch 53/435 (5200-5300)\n",
      "Processing batch 54/435 (5300-5400)\n",
      "Processing batch 55/435 (5400-5500)\n",
      "Processing batch 56/435 (5500-5600)\n",
      "Processing batch 57/435 (5600-5700)\n",
      "Processing batch 58/435 (5700-5800)\n",
      "Processing batch 59/435 (5800-5900)\n",
      "Processing batch 60/435 (5900-6000)\n",
      "Processing batch 61/435 (6000-6100)\n",
      "Processing batch 62/435 (6100-6200)\n",
      "Processing batch 63/435 (6200-6300)\n",
      "Processing batch 64/435 (6300-6400)\n",
      "Processing batch 65/435 (6400-6500)\n",
      "Processing batch 66/435 (6500-6600)\n",
      "Processing batch 67/435 (6600-6700)\n",
      "Processing batch 68/435 (6700-6800)\n",
      "Processing batch 69/435 (6800-6900)\n",
      "Processing batch 70/435 (6900-7000)\n",
      "Processing batch 71/435 (7000-7100)\n",
      "Processing batch 72/435 (7100-7200)\n",
      "Processing batch 73/435 (7200-7300)\n",
      "Processing batch 74/435 (7300-7400)\n",
      "Processing batch 75/435 (7400-7500)\n",
      "Processing batch 76/435 (7500-7600)\n",
      "Processing batch 77/435 (7600-7700)\n",
      "Processing batch 78/435 (7700-7800)\n",
      "Processing batch 79/435 (7800-7900)\n",
      "Processing batch 80/435 (7900-8000)\n",
      "Processing batch 81/435 (8000-8100)\n",
      "Processing batch 82/435 (8100-8200)\n",
      "Processing batch 83/435 (8200-8300)\n",
      "Processing batch 84/435 (8300-8400)\n",
      "Processing batch 85/435 (8400-8500)\n",
      "Processing batch 86/435 (8500-8600)\n",
      "Processing batch 87/435 (8600-8700)\n",
      "Processing batch 88/435 (8700-8800)\n",
      "Processing batch 89/435 (8800-8900)\n",
      "Processing batch 90/435 (8900-9000)\n",
      "Processing batch 91/435 (9000-9100)\n",
      "Processing batch 92/435 (9100-9200)\n",
      "Processing batch 93/435 (9200-9300)\n",
      "Processing batch 94/435 (9300-9400)\n",
      "Processing batch 95/435 (9400-9500)\n",
      "Processing batch 96/435 (9500-9600)\n",
      "Processing batch 97/435 (9600-9700)\n",
      "Processing batch 98/435 (9700-9800)\n",
      "Processing batch 99/435 (9800-9900)\n",
      "Processing batch 100/435 (9900-10000)\n",
      "Processing batch 101/435 (10000-10100)\n",
      "Processing batch 102/435 (10100-10200)\n",
      "Processing batch 103/435 (10200-10300)\n",
      "Processing batch 104/435 (10300-10400)\n",
      "Processing batch 105/435 (10400-10500)\n",
      "Processing batch 106/435 (10500-10600)\n",
      "Processing batch 107/435 (10600-10700)\n",
      "Processing batch 108/435 (10700-10800)\n",
      "Processing batch 109/435 (10800-10900)\n",
      "Processing batch 110/435 (10900-11000)\n",
      "Processing batch 111/435 (11000-11100)\n",
      "Processing batch 112/435 (11100-11200)\n",
      "Processing batch 113/435 (11200-11300)\n",
      "Processing batch 114/435 (11300-11400)\n",
      "Processing batch 115/435 (11400-11500)\n",
      "Processing batch 116/435 (11500-11600)\n",
      "Processing batch 117/435 (11600-11700)\n",
      "Processing batch 118/435 (11700-11800)\n",
      "Processing batch 119/435 (11800-11900)\n",
      "Processing batch 120/435 (11900-12000)\n",
      "Processing batch 121/435 (12000-12100)\n",
      "Processing batch 122/435 (12100-12200)\n",
      "Processing batch 123/435 (12200-12300)\n",
      "Processing batch 124/435 (12300-12400)\n",
      "Processing batch 125/435 (12400-12500)\n",
      "Processing batch 126/435 (12500-12600)\n",
      "Processing batch 127/435 (12600-12700)\n",
      "Processing batch 128/435 (12700-12800)\n",
      "Processing batch 129/435 (12800-12900)\n",
      "Processing batch 130/435 (12900-13000)\n",
      "Processing batch 131/435 (13000-13100)\n",
      "Processing batch 132/435 (13100-13200)\n",
      "Processing batch 133/435 (13200-13300)\n",
      "Processing batch 134/435 (13300-13400)\n",
      "Processing batch 135/435 (13400-13500)\n",
      "Processing batch 136/435 (13500-13600)\n",
      "Processing batch 137/435 (13600-13700)\n",
      "Processing batch 138/435 (13700-13800)\n",
      "Processing batch 139/435 (13800-13900)\n",
      "Processing batch 140/435 (13900-14000)\n",
      "Processing batch 141/435 (14000-14100)\n",
      "Processing batch 142/435 (14100-14200)\n",
      "Processing batch 143/435 (14200-14300)\n",
      "Processing batch 144/435 (14300-14400)\n",
      "Processing batch 145/435 (14400-14500)\n",
      "Processing batch 146/435 (14500-14600)\n",
      "Processing batch 147/435 (14600-14700)\n",
      "Processing batch 148/435 (14700-14800)\n",
      "Processing batch 149/435 (14800-14900)\n",
      "Processing batch 150/435 (14900-15000)\n",
      "Processing batch 151/435 (15000-15100)\n",
      "Processing batch 152/435 (15100-15200)\n",
      "Processing batch 153/435 (15200-15300)\n",
      "Processing batch 154/435 (15300-15400)\n",
      "Processing batch 155/435 (15400-15500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = torch.load(fc[\"embedding_save_path\"] + f\"/sapbert_lora_triplet16.pt\")\n",
    "embedding_exp = embeddings[\"expressions_embeddings\"]\n",
    "embedding_label = embeddings[\"labels_embeddings\"]\n",
    "embedding_exp_q,_ = evaluate(rvq_cosine, embedding_exp)\n",
    "embedding_label_q,_ = evaluate(rvq_cosine, embedding_label)\n",
    "rank = eval_utils.top_k_array_by_batch(df_concept_test_fd, embedding_exp_q, embedding_label_q,cfg.device, 100)\n",
    "mrr_rank = eval_utils.compute_mmr(rank)\n",
    "mrrs_1.append(mrr_rank)\n",
    "models_1.append(\"cosin_4_512\")\n",
    "ranks_1[\"cosin_4_512\"] = rank\n",
    "print(f\"MRR: {mrr_rank}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
